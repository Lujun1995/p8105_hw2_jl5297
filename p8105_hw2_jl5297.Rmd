---
title: "p8105_hw2_jl5297"
author: "Jun Lu"
date: "9/25/2018"
output: github_document
---

## Executive Summary
This my second homework for Data Science, including my solutions to Problems 1, 2 and 3. And I was praciticing data wrangling and tidy data through this homework.

## Load Packages
```{r, warning=FALSE, message=FALSE}
library(tidyverse)
library(readxl)
```

## Problem 1

### 1. Read and clean the data
Read and clean the NYC Transit data
```{r, message=FALSE, warning=FALSE}
nyc = 
    read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>% 
    janitor::clean_names() %>% 
    select(line:entry, vending, ada) %>% 
    mutate(entry = ifelse(entry == "YES", T, F))

nyc
```
The "nyc_transit" dataset extracted data from  "NYC_Transit_Subway_Entrance_And_Exit_Data.csv" document. This dataset has `r nrow(nyc)` rows and `r ncol(nyc)` columns. There are `r nrow(nyc)` observations in this dataset. The nyc_transit dataset contains variables including line, station, name, station latitude / longitude, routes served(route 1-11), entry, vending, entrance type, and ADA compliance. 
      
I load the data, clean the varibales name, select needed variables and convert the entry variable from character (YES vs NO) to a logical variable. These data are not tidy, because there are variables value in columns' names.

### 2. Solution to questions
**a. Count distinct stations**
```{r}
nyc_distinct = distinct(nyc[c("line", "station_name", "ada")])
nrow(nyc_distinct)
```
There are 465 distinct stations.
       
       
**b. Count stations which are ADA compliant**
```{r}
nyc_distinct %>% filter(ada == T) %>% nrow()
```
There are 84 stations which are ADA compliant.
     
          
**c. Calculate proportion of station entrances / exits without vending allow entrance**
```{r}
entran_withoutvending = nyc %>% filter(vending == "NO")
mean(entran_withoutvending$entry)
```
The proportion of station entrances / exits without vending allow entrance is about 0.377.
     
     
### 3. Reform data
Reformat data so that route number and route name are distinct variables. After reforming, I delete the line with NA in route name to make this dataset more tidy.
```{r}
nyc_reform = nyc %>% 
    gather(key = route_number, value = route_name, route1:route11) %>% 
    select(line, station_name, route_number, route_name, ada, everything()) %>%
    filter(!is.na(route_name)) %>%  
    arrange(line, station_name)

nyc_reform
```

### 4. Solutions to questions
**a. Count distinct stations which serve the A train**
```{r}
nyc_reform_distinct = distinct(nyc_reform[c("line", "station_name",  "route_name", "ada")])
nyc_reform_distinct %>% filter(route_name == "A") %>% nrow()
```
There 60 distinct stations which serve the A train.

**b. Count how many distinct stations which serve the A train are ADA compliant**
```{r}
nyc_reform_distinct %>% filter(route_name == "A", ada == T) %>% nrow()
```
There are 17 distinct stations which serve the A train and are ADA compliant.

## Problem 2
### 1. Read and clean data
**a. Read and clean the Mr. Trash Wheel sheet.**
```{r}
trash = read_excel("./data/HealthyHarborWaterWheelTotals2018-7-28.xlsx",
                   sheet = 1, range = cell_cols("A:N")) %>% 
    janitor::clean_names() %>% 
    rename(weight = weight_tons, volume = volume_cubic_yards) %>% 
    filter(!is.na(dumpster)) %>% 
    mutate(sports_balls = as.integer(round(sports_balls, 0)))

trash
```


**b. Read and clean precipitation data for 2017.**
```{r}
precip_2017 = read_excel("./data/HealthyHarborWaterWheelTotals2018-7-28.xlsx",
                         sheet = 4, range = "A2:B14") %>%
    janitor::clean_names() %>% 
    rename(precipitation = total) %>% 
    filter(!is.na(precipitation)) %>% 
    mutate(year = "2017")
```

**c. Read and clean precipitation data for 2016.**
```{r}
precip_2016 = read_excel("./data/HealthyHarborWaterWheelTotals2018-7-28.xlsx",
                         sheet = 5, range = "A2:B14") %>%
    janitor::clean_names() %>% 
    rename(precipitation = total) %>% 
    filter(!is.na(precipitation)) %>% 
    mutate(year = "2016")
```

**d. Combine datasets and convert month to a character variable**
```{r}
precip = bind_rows(precip_2016, precip_2017) %>% 
    select(year, everything()) %>% 
    mutate(month = month.name[month])

precip
```

### 2. Describe the data
The "trash"" dataset extracted data from sheet 1 of  "HealthyHarborWaterWheelTotals2018-7-28.xlsx". It has `r nrow(trash)` rows and `r ncol(trash)` columns. There are `r nrow(trash)` observations in this dataset. And there are 14 variables in this dataset, including dumpster number, month, year, date, weight, volume, the number of a specific trash it collected and so on. For example, from the dataset we can know that on 2014-05-16 the dumpster 1 collected 1450 plastic bottles.
   
   
The "precip" dataset merged data from sheet 4 and sheet 5 of document "HealthyHarborWaterWheelTotals2018-7-28.xlsx". It has `r nrow(precip)` rows  and `r ncol(precip)` columns. There are `r nrow(precip)` observations and `r ncol(precip)` variables including year, month and total precipitation in this dataset. For example, from the dataset we can know that on in January 2016 it collected 3.23 total precipitation.

### 3. Solutions to questions
**a. Total precipitation in 2017**
```{r}
sum(precip_2017$precipitation)
```
Total precipitation in 2017 is 32.93.

**b. The median number of sports balls in a dumpster in 2016**
```{r}
trash %>% filter(year == "2016") %>% summarise(median(sports_balls))
    
```
The median number of sports balls in a dumpster in 2016 is 26.

## Problem 3
### 1. Load the data
Need to install package p8105.datasets firstly on your computer.
```{r}
library(p8105.datasets)
data("brfss_smart2010")
```

### 2. Clean the data
```{r}
brfss_tidy = 
    brfss_smart2010 %>% 
    janitor::clean_names() %>%
    filter(topic == "Overall Health") %>% 
    select(-(class:question), -sample_size, -(confidence_limit_low:geo_location)) %>% 
    spread(key = response, value = data_value) %>% 
    janitor::clean_names() %>% 
    mutate(excellent_verygood_proportion = excellent + very_good) 

brfss_tidy
```

### 3. Solutions to questions
**a. How many unique locations are included in the dataset? Is every state represented? What state is observed the most?**
```{r}
# Calculate the number of unique locations
length(unique(brfss_tidy$locationdesc))

# Find whether every state is represented
length(unique(brfss_tidy$locationabbr))

# Find which state is observed the most
getmode <- function(v) {
   uniqv <- unique(v)
   uniqv[which.max(tabulate(match(v, uniqv)))]
}
getmode(brfss_tidy$locationabbr)
```
   
* There are 404 unique locations
* Every state is reprsented
* NJ is observed most.

**b. In 2002, what is the median of the “Excellent” response value?**
```{r}
brfss_tidy %>% 
    filter(year == "2002") %>% 
    summarise(median_2002 = median(excellent, na.rm = T))
```
The median of the “Excellent” response value is 23.6.

**c. Make a histogram of “Excellent” response values in the year 2002**
```{r, warning=FALSE, message=FALSE}
brfss_tidy %>% 
    filter(year == 2002) %>% 
    ggplot(aes(x = excellent)) + 
    geom_histogram() +
    labs(
    title = "Histogram of “Excellent” response values in the year 2002",
    x = '"Excellent" response values',
    y = "Count",
    caption = "Data from brfss_smart2010") +
    theme_bw() 
    
ggsave("histogram.jpg")
```

**d. Make a scatterplot showing the proportion of “Excellent” response values in New York County and Queens County (both in NY State) in each year from 2002 to 2010.**
```{r}
brfss_tidy %>% 
    filter(locationdesc %in% c("NY - New York County", "NY - Queens County")) %>% 
    ggplot(aes(x = year, y = excellent, color = locationdesc)) +
    geom_point(size = 3) + 
    geom_line(alpha = 0.1) +
    labs(
    x = "Year",
    y = "The proportion of “Excellent” response values -(%)",
    caption = "Data from brfss_smart2010") +
    theme_bw() +
    theme(legend.position = "bottom")
    
ggsave("scatterplot.jpg")
```                                                                                                                             
From this scatterplot, we can know that the proportion of 'Excellent' response of New York County is always higher than Queens County.
 







